{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure Maintenence Prediction\n",
    "\n",
    "https://www.kaggle.com/datasets/arnabbiswas1/microsoft-azure-predictive-maintenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>machineID</th>\n",
       "      <th>errorID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-03 07:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>error1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-03 20:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>error3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-04 06:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>error5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-10 15:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>error4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-22 10:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>error4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime  machineID errorID\n",
       "0  2015-01-03 07:00:00          1  error1\n",
       "1  2015-01-03 20:00:00          1  error3\n",
       "2  2015-01-04 06:00:00          1  error5\n",
       "3  2015-01-10 15:00:00          1  error4\n",
       "4  2015-01-22 10:00:00          1  error4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import kurtosis\n",
    "import pywt\n",
    "from scipy.fft import fft\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils import resample\n",
    "\n",
    "telemetry_df = pd.read_csv('telemetry.csv')\n",
    "errors_df = pd.read_csv('errors.csv')\n",
    "\n",
    "errors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>errorID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>machineID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           datetime  errorID\n",
       "machineID                   \n",
       "22               60       60"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_df.groupby('machineID').count().sort_values(ascending=False, by='errorID').head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>volt</th>\n",
       "      <th>rotate</th>\n",
       "      <th>pressure</th>\n",
       "      <th>vibration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>machineID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>8761</td>\n",
       "      <td>8761</td>\n",
       "      <td>8761</td>\n",
       "      <td>8761</td>\n",
       "      <td>8761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           datetime  volt  rotate  pressure  vibration\n",
       "machineID                                             \n",
       "22             8761  8761    8761      8761       8761"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telemetry_df[telemetry_df['machineID'] == 22].groupby('machineID').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_df['datetime'] = errors_df['datetime'].astype('datetime64[ns]')\n",
    "telemetry_df['datetime'] = telemetry_df['datetime'].astype('datetime64[ns]')\n",
    "\n",
    "# Selecionamos a máquina com mais ocorrências de erros\n",
    "mID = 22\n",
    "\n",
    "errors_df = errors_df[errors_df['machineID'] == mID]\n",
    "telemetry_df = telemetry_df[telemetry_df['machineID'] == mID]\n",
    "\n",
    "errors_df.drop(['machineID'], axis=1, inplace=True)\n",
    "telemetry_df.drop(['machineID'], axis=1, inplace=True)\n",
    "\n",
    "# Preprocess - qualquer erro vira 1\n",
    "errors_df['error'] = errors_df['errorID'].apply(lambda x: 1)\n",
    "errors_df = errors_df.drop('errorID', axis=1)\n",
    "\n",
    "# Merge telemetry com errors pela data, e preenche com 0 as ocorrências sem erro\n",
    "merged_df = telemetry_df.merge(errors_df, on=['datetime'], how='left')\n",
    "merged_df['error'] = merged_df['error'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Janela de tempo para extrair as características\n",
    "window_size = 3  \n",
    "data_windows = []\n",
    "labels = []\n",
    "\n",
    "machine_data = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para extração de características\n",
    "def extract_features(window):\n",
    "    features = {}\n",
    "    if len(window) > 0:\n",
    "        features['mean'] = window.mean()\n",
    "        features['median'] = window.median()\n",
    "        features['std'] = window.std()\n",
    "        features['kurtosis'] = kurtosis(window)\n",
    "\n",
    "        # Wavelet transform\n",
    "        coeffs = pywt.wavedec(window, 'db1', level=1)\n",
    "        features['wavelet'] = np.mean(coeffs[0])  \n",
    "\n",
    "        # Fourier transform\n",
    "        #window_np = np.array(window)\n",
    "        #fourier = fft(window_np)\n",
    "        #features['fourier_mean'] = np.mean(np.abs(fourier))\n",
    "        #features['fourier_std'] = np.std(np.abs(fourier))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checando se as 15 horas anteriores são normais\n",
    "machine_data['condition_met'] = 0\n",
    "\n",
    "for i in range(15, len(machine_data)):\n",
    "    if machine_data['error'].iloc[i-15:i].sum() == 0:\n",
    "        machine_data.loc[i, 'condition_met'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample instâncias normais \n",
    "num = 100\n",
    "np.random.seed(42)\n",
    "normal_indices = machine_data[(machine_data['error'] == 0) & (machine_data['condition_met'] == 1)].index\n",
    "sampled_normal_indices = np.random.choice(normal_indices, size=min(num, len(normal_indices)), replace=False)\n",
    "sampled_indices = sorted(list(sampled_normal_indices) + list(machine_data[machine_data['error'] == 1].index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sampled_indices:\n",
    "    if i >= window_size and i < len(machine_data):\n",
    "        window = machine_data.iloc[i-window_size:i]\n",
    "        features = {}\n",
    "        for column in ['volt', 'rotate', 'pressure', 'vibration']:\n",
    "            column_features = extract_features(window[column])\n",
    "            for key in column_features:\n",
    "                features[f'{column}_{key}'] = column_features[key]\n",
    "        label = machine_data.iloc[i]['error']\n",
    "        data_windows.append(features)\n",
    "        labels.append(label)\n",
    "\n",
    "# Cria df com as características\n",
    "feature_df = pd.DataFrame(data_windows)\n",
    "feature_df['label'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[26  4]\n",
      " [ 7 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.87      0.83        30\n",
      "         1.0       0.73      0.61      0.67        18\n",
      "\n",
      "    accuracy                           0.77        48\n",
      "   macro avg       0.76      0.74      0.75        48\n",
      "weighted avg       0.77      0.77      0.77        48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Downsample a classe normal - para evitar que o algoritmo considere tudo como normal\n",
    "sample = 100\n",
    "normal_df = feature_df[feature_df['label'] == 0]\n",
    "error_df = feature_df[feature_df['label'] == 1]\n",
    "\n",
    "normal_df_downsampled = resample(normal_df, replace=False, n_samples=sample, random_state=42)\n",
    "balanced_df = pd.concat([normal_df_downsampled, error_df])\n",
    "\n",
    "# Treino e teste\n",
    "X = balanced_df.drop('label', axis=1)\n",
    "y = balanced_df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Random Forest model\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Print metrics\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 1s 71ms/step - loss: 0.6631 - accuracy: 0.5900 - val_loss: 0.5410 - val_accuracy: 0.7500\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6436 - accuracy: 0.6100 - val_loss: 0.5130 - val_accuracy: 0.7500\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6400 - accuracy: 0.6200 - val_loss: 0.5088 - val_accuracy: 0.8333\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6285 - accuracy: 0.6400 - val_loss: 0.5074 - val_accuracy: 0.8333\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6263 - accuracy: 0.6400 - val_loss: 0.4992 - val_accuracy: 0.7500\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6236 - accuracy: 0.6600 - val_loss: 0.5083 - val_accuracy: 0.7500\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6156 - accuracy: 0.6700 - val_loss: 0.4839 - val_accuracy: 0.8333\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6182 - accuracy: 0.6500 - val_loss: 0.4662 - val_accuracy: 0.8333\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6168 - accuracy: 0.6700 - val_loss: 0.4569 - val_accuracy: 0.7500\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6103 - accuracy: 0.6600 - val_loss: 0.4572 - val_accuracy: 0.9167\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "[[29  1]\n",
      " [12  6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.97      0.82        30\n",
      "           1       0.86      0.33      0.48        18\n",
      "\n",
      "    accuracy                           0.73        48\n",
      "   macro avg       0.78      0.65      0.65        48\n",
      "weighted avg       0.76      0.73      0.69        48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Criar janelas de tempo para LSTM\n",
    "def create_windows(df, samples_per_window, indices):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in indices:\n",
    "        if i >= samples_per_window and i < len(df):\n",
    "            window = df.iloc[i-samples_per_window:i]\n",
    "            X.append(window[['volt', 'rotate', 'pressure', 'vibration']].values)\n",
    "            y.append(df.iloc[i]['error'])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X, y = create_windows(machine_data, window_size, sampled_indices)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "y_categorical = to_categorical(y_encoded)\n",
    "\n",
    "# Teino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_categorical, test_size=0.3, random_state=42, stratify=y_categorical)\n",
    "\n",
    "# LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(window_size, 4)))\n",
    "model.add(Dense(y_categorical.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=10, validation_split=0.1)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(confusion_matrix(y_true_classes, y_pred_classes))\n",
    "print(classification_report(y_true_classes, y_pred_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HAR - Human Activity Recognition\n",
    "\n",
    "https://www.kaggle.com/datasets/uciml/human-activity-recognition-with-smartphones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Downstairs       0.32      0.13      0.19     20129\n",
      "     Jogging       0.70      0.70      0.70     65138\n",
      "     Sitting       0.98      0.98      0.98     12099\n",
      "    Standing       0.83      0.87      0.85      9591\n",
      "    Upstairs       0.35      0.15      0.21     24350\n",
      "     Walking       0.60      0.77      0.67     83418\n",
      "\n",
      "    accuracy                           0.64    214725\n",
      "   macro avg       0.63      0.60      0.60    214725\n",
      "weighted avg       0.60      0.64      0.61    214725\n",
      "\n",
      "Accuracy: 0.64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "df = pd.read_csv('time_series_data_human_activities.csv')\n",
    "\n",
    "# Convertendo para segundos\n",
    "df['time'] = df['timestamp'] / 1e9\n",
    "\n",
    "# Treino e teste\n",
    "X = df[['x-axis', 'y-axis', 'z-axis']]\n",
    "y = df['activity']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Random Forest\n",
    "\n",
    "#OBS.: Demora para rodar (2 min aqui no meu PC)! Paciência :)\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Downstairs       0.82      0.63      0.71      2027\n",
      "     Jogging       0.96      0.99      0.97      6429\n",
      "     Sitting       1.00      0.98      0.99      1163\n",
      "    Standing       0.98      0.98      0.98       963\n",
      "    Upstairs       0.81      0.67      0.73      2514\n",
      "     Walking       0.89      0.98      0.93      8377\n",
      "\n",
      "    accuracy                           0.91     21473\n",
      "   macro avg       0.91      0.87      0.89     21473\n",
      "weighted avg       0.91      0.91      0.91     21473\n",
      "\n",
      "Accuracy: 0.91\n"
     ]
    }
   ],
   "source": [
    "from scipy.signal import welch\n",
    "import pywt\n",
    "\n",
    "window_size = 1  # em segundos\n",
    "overlap = 0.5  # 50% overlap\n",
    "\n",
    "# Sampling rate\n",
    "sampling_rate = int(1 / (df['time'].iloc[1] - df['time'].iloc[0]))\n",
    "samples_per_window = int(window_size * sampling_rate)\n",
    "step_size = int(samples_per_window * (1 - overlap))\n",
    "\n",
    "# Extração de características\n",
    "def extract_features(window):\n",
    "    features = {}\n",
    "    for axis in ['x-axis', 'y-axis', 'z-axis']:\n",
    "        # Time domain features\n",
    "        features[f'{axis}_mean'] = np.mean(window[axis])\n",
    "        features[f'{axis}_std'] = np.std(window[axis])\n",
    "        features[f'{axis}_max'] = np.max(window[axis])\n",
    "        features[f'{axis}_min'] = np.min(window[axis])\n",
    "        \n",
    "        # Frequency domain features using Welch's method\n",
    "        #freqs, psd = welch(window[axis], fs=sampling_rate)\n",
    "        #features[f'{axis}_psd_mean'] = np.mean(psd)\n",
    "        #features[f'{axis}_psd_std'] = np.std(psd)\n",
    "        \n",
    "        # Wavelet transform features\n",
    "        coeffs = pywt.wavedec(window[axis], 'db1', level=2)\n",
    "        for i, coeff in enumerate(coeffs):\n",
    "            features[f'{axis}_wavelet_{i}_mean'] = np.mean(coeff)\n",
    "            features[f'{axis}_wavelet_{i}_std'] = np.std(coeff)\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Preparando o dataset\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for start in range(0, len(df) - samples_per_window, step_size):\n",
    "    end = start + samples_per_window\n",
    "    window = df.iloc[start:end]\n",
    "    if len(window) == samples_per_window:\n",
    "        features = extract_features(window)\n",
    "        X.append(features)\n",
    "        y.append(window['activity'].mode()[0])  \n",
    "\n",
    "X = pd.DataFrame(X)\n",
    "y = np.array(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Random Forest\n",
    "# Tempo no meu PC: 1:40\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred):.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1074/1074 [==============================] - 12s 11ms/step - loss: 0.4832 - accuracy: 0.8290 - val_loss: 0.2999 - val_accuracy: 0.8941\n",
      "Epoch 2/10\n",
      "1074/1074 [==============================] - 11s 10ms/step - loss: 0.2577 - accuracy: 0.9112 - val_loss: 0.2347 - val_accuracy: 0.9183\n",
      "Epoch 3/10\n",
      "1074/1074 [==============================] - 11s 10ms/step - loss: 0.1972 - accuracy: 0.9330 - val_loss: 0.1897 - val_accuracy: 0.9360\n",
      "Epoch 4/10\n",
      "1074/1074 [==============================] - 11s 10ms/step - loss: 0.1636 - accuracy: 0.9454 - val_loss: 0.1697 - val_accuracy: 0.9445\n",
      "Epoch 5/10\n",
      "1074/1074 [==============================] - 11s 10ms/step - loss: 0.1405 - accuracy: 0.9537 - val_loss: 0.1557 - val_accuracy: 0.9491\n",
      "Epoch 6/10\n",
      "1074/1074 [==============================] - 11s 10ms/step - loss: 0.1249 - accuracy: 0.9592 - val_loss: 0.1390 - val_accuracy: 0.9547\n",
      "Epoch 7/10\n",
      "1074/1074 [==============================] - 10s 10ms/step - loss: 0.1136 - accuracy: 0.9623 - val_loss: 0.1405 - val_accuracy: 0.9542\n",
      "Epoch 8/10\n",
      "1074/1074 [==============================] - 11s 10ms/step - loss: 0.1012 - accuracy: 0.9668 - val_loss: 0.1578 - val_accuracy: 0.9495\n",
      "Epoch 9/10\n",
      "1074/1074 [==============================] - 11s 10ms/step - loss: 0.0903 - accuracy: 0.9706 - val_loss: 0.1356 - val_accuracy: 0.9572\n",
      "Epoch 10/10\n",
      "1074/1074 [==============================] - 11s 10ms/step - loss: 0.0836 - accuracy: 0.9720 - val_loss: 0.1324 - val_accuracy: 0.9572\n",
      "672/672 [==============================] - 2s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86      2027\n",
      "           1       0.98      0.99      0.99      6429\n",
      "           2       0.99      0.98      0.98      1163\n",
      "           3       0.97      0.98      0.98       963\n",
      "           4       0.86      0.86      0.86      2514\n",
      "           5       0.98      0.97      0.98      8377\n",
      "\n",
      "    accuracy                           0.96     21473\n",
      "   macro avg       0.94      0.94      0.94     21473\n",
      "weighted avg       0.96      0.96      0.96     21473\n",
      "\n",
      "Accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Criar janelas de tempo\n",
    "def create_windows(df, samples_per_window, step_size):\n",
    "    X = []\n",
    "    y = []\n",
    "    for start in range(0, len(df) - samples_per_window, step_size):\n",
    "        end = start + samples_per_window\n",
    "        window = df.iloc[start:end]\n",
    "        if len(window) == samples_per_window:\n",
    "            X.append(window[['x-axis', 'y-axis', 'z-axis']].values)\n",
    "            y.append(window['activity'].mode()[0]) \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X, y = create_windows(df, samples_per_window, step_size)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "y_categorical = to_categorical(y_encoded)\n",
    "\n",
    "# Treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_categorical, test_size=0.2, random_state=42)\n",
    "\n",
    "# LSTM model\n",
    "# Tempo no meu PC: 2:05\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(samples_per_window, 3)))\n",
    "model.add(Dense(y_categorical.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(classification_report(y_true_classes, y_pred_classes))\n",
    "print(f'Accuracy: {accuracy_score(y_true_classes, y_pred_classes):.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "koru",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
